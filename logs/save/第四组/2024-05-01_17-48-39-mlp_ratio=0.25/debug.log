2024-05-01 17:48:39   Arguments: Namespace(aggregator_name='token_module', backbone_name='dinov2', device='cuda', dim=768, epochs_num=80, foundation_model_path='pth/dinov2_vitb14_pretrain.pth', infer_batch_size=300, kernel_size=3, lr=0.0001, mlp_ratio=0.25, nc=4096, num_trainable_blocks=4, num_workers=4, optim='adam', patience=3, recall_values=[1, 5, 10, 100], resize=[224, 224], save_dir='logs/2024-05-01_17-48-39', seed=0, train_batch_size=160, val_set_names=['msls_val'])
2024-05-01 17:48:39   The outputs are being saved in logs/2024-05-01_17-48-39
2024-05-01 17:48:39   validation dataset names:['msls_val']
2024-05-01 17:48:39   Using 2 GPUs and 64 CPUs
2024-05-01 17:48:39   using MLP layer as FFN
2024-05-01 17:48:42   GeoLocalizationNet(
  (backbone): Dinov2(
    (model): DinoVisionTransformer(
      (patch_embed): PatchEmbed(
        (proj): Conv2d(3, 768, kernel_size=(14, 14), stride=(14, 14))
        (norm): Identity()
      )
      (blocks): ModuleList(
        (0): NestedTensorBlock(
          (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          (attn): MemEffAttention(
            (qkv): Linear(in_features=768, out_features=2304, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=768, out_features=768, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
          )
          (ls1): LayerScale()
          (drop_path1): Identity()
          (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (act): GELU(approximate='none')
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
          (ls2): LayerScale()
          (drop_path2): Identity()
        )
        (1): NestedTensorBlock(
          (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          (attn): MemEffAttention(
            (qkv): Linear(in_features=768, out_features=2304, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=768, out_features=768, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
          )
          (ls1): LayerScale()
          (drop_path1): Identity()
          (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (act): GELU(approximate='none')
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
          (ls2): LayerScale()
          (drop_path2): Identity()
        )
        (2): NestedTensorBlock(
          (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          (attn): MemEffAttention(
            (qkv): Linear(in_features=768, out_features=2304, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=768, out_features=768, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
          )
          (ls1): LayerScale()
          (drop_path1): Identity()
          (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (act): GELU(approximate='none')
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
          (ls2): LayerScale()
          (drop_path2): Identity()
        )
        (3): NestedTensorBlock(
          (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          (attn): MemEffAttention(
            (qkv): Linear(in_features=768, out_features=2304, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=768, out_features=768, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
          )
          (ls1): LayerScale()
          (drop_path1): Identity()
          (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (act): GELU(approximate='none')
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
          (ls2): LayerScale()
          (drop_path2): Identity()
        )
        (4): NestedTensorBlock(
          (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          (attn): MemEffAttention(
            (qkv): Linear(in_features=768, out_features=2304, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=768, out_features=768, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
          )
          (ls1): LayerScale()
          (drop_path1): Identity()
          (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (act): GELU(approximate='none')
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
          (ls2): LayerScale()
          (drop_path2): Identity()
        )
        (5): NestedTensorBlock(
          (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          (attn): MemEffAttention(
            (qkv): Linear(in_features=768, out_features=2304, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=768, out_features=768, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
          )
          (ls1): LayerScale()
          (drop_path1): Identity()
          (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (act): GELU(approximate='none')
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
          (ls2): LayerScale()
          (drop_path2): Identity()
        )
        (6): NestedTensorBlock(
          (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          (attn): MemEffAttention(
            (qkv): Linear(in_features=768, out_features=2304, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=768, out_features=768, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
          )
          (ls1): LayerScale()
          (drop_path1): Identity()
          (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (act): GELU(approximate='none')
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
          (ls2): LayerScale()
          (drop_path2): Identity()
        )
        (7): NestedTensorBlock(
          (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          (attn): MemEffAttention(
            (qkv): Linear(in_features=768, out_features=2304, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=768, out_features=768, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
          )
          (ls1): LayerScale()
          (drop_path1): Identity()
          (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (act): GELU(approximate='none')
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
          (ls2): LayerScale()
          (drop_path2): Identity()
        )
        (8): NestedTensorBlock(
          (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          (attn): MemEffAttention(
            (qkv): Linear(in_features=768, out_features=2304, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=768, out_features=768, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
          )
          (ls1): LayerScale()
          (drop_path1): Identity()
          (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (act): GELU(approximate='none')
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
          (ls2): LayerScale()
          (drop_path2): Identity()
        )
        (9): NestedTensorBlock(
          (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          (attn): MemEffAttention(
            (qkv): Linear(in_features=768, out_features=2304, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=768, out_features=768, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
          )
          (ls1): LayerScale()
          (drop_path1): Identity()
          (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (act): GELU(approximate='none')
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
          (ls2): LayerScale()
          (drop_path2): Identity()
        )
        (10): NestedTensorBlock(
          (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          (attn): MemEffAttention(
            (qkv): Linear(in_features=768, out_features=2304, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=768, out_features=768, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
          )
          (ls1): LayerScale()
          (drop_path1): Identity()
          (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (act): GELU(approximate='none')
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
          (ls2): LayerScale()
          (drop_path2): Identity()
        )
        (11): NestedTensorBlock(
          (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          (attn): MemEffAttention(
            (qkv): Linear(in_features=768, out_features=2304, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=768, out_features=768, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
          )
          (ls1): LayerScale()
          (drop_path1): Identity()
          (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (act): GELU(approximate='none')
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
          (ls2): LayerScale()
          (drop_path2): Identity()
        )
      )
      (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (head): Identity()
    )
  )
  (aggregator): TokenMudule(
    (token_block): TokenBlock(
      (space_self_aware): SpaceSelfAware(
        (pad): ZeroPad2d((1, 1, 2, 0))
        (unfold): Unfold(kernel_size=(3, 3), dilation=1, padding=0, stride=1)
      )
      (space_fusion): Sequential(
        (0): L2Norm()
        (1): GeneralizedMeanPooling(3.0, output_size=1)
      )
      (channel): Mlp(
        (fc1): Linear(in_features=768, out_features=192, bias=True)
        (act): GELU(approximate='none')
        (drop1): Dropout(p=0.0, inplace=False)
        (fc2): Linear(in_features=192, out_features=768, bias=True)
        (drop2): Dropout(p=0.0, inplace=False)
      )
    )
    (head): GeMHead(
      (pool): GeneralizedMeanPooling(3.0, output_size=1)
      (fc): Linear(in_features=768, out_features=4096, bias=True)
    )
  )
)
2024-05-01 17:48:44   Val set: < MSLS, msls-val - #database: 18871; #queries: 747 >
2024-05-01 17:48:44   Start training epoch: 00
2024-05-01 18:08:14   Finished epoch 00 in 0:19:30, average epoch loss = 0.7985
2024-05-01 18:09:12   Ranking results: msls_val R@1: 0.8351, R@5: 0.9081, R@10: 0.9230, R@15: 0.9365, R@20: 0.9486, R@50: 0.9581, R@100: 0.9608
2024-05-01 18:09:14   Improved: previous msls-val best R@1 = 0.0000, current R@1 = 0.8351
2024-05-01 18:09:14   Start training epoch: 01
2024-05-01 18:28:42   Finished epoch 01 in 0:19:27, average epoch loss = 0.4571
2024-05-01 18:29:40   Ranking results: msls_val R@1: 0.8554, R@5: 0.9324, R@10: 0.9405, R@15: 0.9514, R@20: 0.9541, R@50: 0.9662, R@100: 0.9703
2024-05-01 18:29:47   Improved: previous msls-val best R@1 = 0.8351, current R@1 = 0.8554
2024-05-01 18:29:47   Start training epoch: 02
2024-05-01 18:49:14   Finished epoch 02 in 0:19:26, average epoch loss = 0.3833
2024-05-01 18:50:11   Ranking results: msls_val R@1: 0.8608, R@5: 0.9311, R@10: 0.9405, R@15: 0.9486, R@20: 0.9514, R@50: 0.9608, R@100: 0.9689
2024-05-01 18:50:18   Improved: previous msls-val best R@1 = 0.8554, current R@1 = 0.8608
2024-05-01 18:50:18   Start training epoch: 03
2024-05-01 19:09:45   Finished epoch 03 in 0:19:27, average epoch loss = 0.3251
2024-05-01 19:10:43   Ranking results: msls_val R@1: 0.8703, R@5: 0.9351, R@10: 0.9486, R@15: 0.9527, R@20: 0.9541, R@50: 0.9635, R@100: 0.9703
2024-05-01 19:10:50   Improved: previous msls-val best R@1 = 0.8608, current R@1 = 0.8703
2024-05-01 19:10:50   Start training epoch: 04
2024-05-01 19:30:18   Finished epoch 04 in 0:19:28, average epoch loss = 0.2971
2024-05-01 19:31:15   Ranking results: msls_val R@1: 0.8743, R@5: 0.9351, R@10: 0.9432, R@15: 0.9486, R@20: 0.9581, R@50: 0.9730, R@100: 0.9730
2024-05-01 19:31:21   Improved: previous msls-val best R@1 = 0.8703, current R@1 = 0.8743
2024-05-01 19:31:21   Start training epoch: 05
2024-05-01 19:50:50   Finished epoch 05 in 0:19:28, average epoch loss = 0.2783
2024-05-01 19:51:47   Ranking results: msls_val R@1: 0.8811, R@5: 0.9365, R@10: 0.9486, R@15: 0.9554, R@20: 0.9581, R@50: 0.9662, R@100: 0.9716
2024-05-01 19:51:53   Improved: previous msls-val best R@1 = 0.8743, current R@1 = 0.8811
2024-05-01 19:51:53   Start training epoch: 06
2024-05-01 20:11:21   Finished epoch 06 in 0:19:28, average epoch loss = 0.2499
2024-05-01 20:12:19   Ranking results: msls_val R@1: 0.8743, R@5: 0.9378, R@10: 0.9459, R@15: 0.9527, R@20: 0.9608, R@50: 0.9689, R@100: 0.9716
2024-05-01 20:12:23   Not improved: 1 / 3: msls-val best R@1 = 0.8811, current R@1 = 0.8743
2024-05-01 20:12:23   Start training epoch: 07
2024-05-01 20:31:51   Finished epoch 07 in 0:19:28, average epoch loss = 0.2354
2024-05-01 20:32:48   Ranking results: msls_val R@1: 0.8851, R@5: 0.9392, R@10: 0.9486, R@15: 0.9541, R@20: 0.9649, R@50: 0.9689, R@100: 0.9730
2024-05-01 20:32:54   Improved: previous msls-val best R@1 = 0.8811, current R@1 = 0.8851
2024-05-01 20:32:54   Start training epoch: 08
2024-05-01 20:52:22   Finished epoch 08 in 0:19:27, average epoch loss = 0.2273
2024-05-01 20:53:19   Ranking results: msls_val R@1: 0.8730, R@5: 0.9324, R@10: 0.9486, R@15: 0.9554, R@20: 0.9608, R@50: 0.9689, R@100: 0.9743
2024-05-01 20:53:23   Not improved: 1 / 3: msls-val best R@1 = 0.8851, current R@1 = 0.8730
2024-05-01 20:53:23   Start training epoch: 09
2024-05-01 21:12:51   Finished epoch 09 in 0:19:28, average epoch loss = 0.2116
2024-05-01 21:13:49   Ranking results: msls_val R@1: 0.8770, R@5: 0.9351, R@10: 0.9432, R@15: 0.9541, R@20: 0.9595, R@50: 0.9662, R@100: 0.9743
2024-05-01 21:13:52   Not improved: 2 / 3: msls-val best R@1 = 0.8851, current R@1 = 0.8770
2024-05-01 21:13:52   Start training epoch: 10
2024-05-01 21:33:20   Finished epoch 10 in 0:19:27, average epoch loss = 0.2022
2024-05-01 21:34:18   Ranking results: msls_val R@1: 0.8824, R@5: 0.9419, R@10: 0.9514, R@15: 0.9568, R@20: 0.9595, R@50: 0.9730, R@100: 0.9757
2024-05-01 21:34:21   Not improved: 3 / 3: msls-val best R@1 = 0.8851, current R@1 = 0.8824
2024-05-01 21:34:21   Performance did not improve for 3 epochs. Stop training.
2024-05-01 21:34:21   Best  msls-val best R@1 = 0.8851
2024-05-01 21:34:21   Trained for 11 epochs, in total in 3:45:42
2024-05-01 21:34:21   Val set: < MSLS, msls-val - #database: 18871; #queries: 747 >
2024-05-01 21:34:21   Val set: < Tokyo247Dataset, Tokyo - #database: 75984; #queries: 423 >
2024-05-01 21:34:21   Val set: < SPEDDataset, SPED - #database: 607; #queries: 607 >
2024-05-01 21:34:21   Val set: < NordlandDataset, nordland - #database: 27592; #queries: 2760 >
2024-05-01 21:34:21   Val set: < WholeDatasetFromStruct, pitts30k_val - #database: 10000; #queries: 7608 >
2024-05-01 21:34:21   Val set: < WholeDatasetFromStruct, pitts30k_test - #database: 10000; #queries: 6816 >
2024-05-01 21:34:22   Val set: < WholeDatasetFromStruct, pitts250k_test - #database: 83952; #queries: 8280 >
2024-05-01 21:34:22   Val set: < WholeDatasetFromStruct, pitts250k_val - #database: 78648; #queries: 7608 >
2024-05-01 21:34:22   Test *best* model on test set
2024-05-01 21:35:20   Ranking results: msls_val R@1: 0.8851, R@5: 0.9392, R@10: 0.9486, R@15: 0.9541, R@20: 0.9649, R@50: 0.9689, R@100: 0.9730
2024-05-01 21:41:29   Ranking results: tokyo247 R@1: 0.8061, R@5: 0.9007, R@10: 0.9196, R@15: 0.9267, R@20: 0.9314, R@50: 0.9433, R@100: 0.9527
2024-05-01 21:41:34   Ranking results: SPED R@1: 0.8567, R@5: 0.9242, R@10: 0.9374, R@15: 0.9489, R@20: 0.9555, R@50: 0.9703, R@100: 0.9802
2024-05-01 21:43:09   Ranking results: nordland R@1: 0.5406, R@5: 0.7181, R@10: 0.7801, R@15: 0.8127, R@20: 0.8297, R@50: 0.8899, R@100: 0.9290
2024-05-01 21:44:09   Ranking results: pitts30k_val R@1: 0.9430, R@5: 0.9866, R@10: 0.9933, R@15: 0.9951, R@20: 0.9959, R@50: 0.9984, R@100: 0.9993
2024-05-01 21:45:06   Ranking results: pitts30k_test R@1: 0.9065, R@5: 0.9523, R@10: 0.9674, R@15: 0.9729, R@20: 0.9758, R@50: 0.9849, R@100: 0.9903
2024-05-01 21:50:53   Ranking results: pitts250k_test R@1: 0.9362, R@5: 0.9789, R@10: 0.9878, R@15: 0.9908, R@20: 0.9919, R@50: 0.9957, R@100: 0.9971
2024-05-01 21:56:12   Ranking results: pitts250k_val R@1: 0.9402, R@5: 0.9838, R@10: 0.9913, R@15: 0.9937, R@20: 0.9949, R@50: 0.9975, R@100: 0.9989
2024-05-01 21:56:12   Test *last* model on test set
2024-05-01 21:57:11   Ranking results: msls_val R@1: 0.8824, R@5: 0.9419, R@10: 0.9514, R@15: 0.9568, R@20: 0.9595, R@50: 0.9730, R@100: 0.9757
2024-05-01 22:03:26   Ranking results: tokyo247 R@1: 0.8322, R@5: 0.9149, R@10: 0.9267, R@15: 0.9291, R@20: 0.9291, R@50: 0.9409, R@100: 0.9598
2024-05-01 22:03:32   Ranking results: SPED R@1: 0.8501, R@5: 0.9143, R@10: 0.9407, R@15: 0.9522, R@20: 0.9588, R@50: 0.9703, R@100: 0.9835
2024-05-01 22:05:06   Ranking results: nordland R@1: 0.5246, R@5: 0.7123, R@10: 0.7703, R@15: 0.8033, R@20: 0.8264, R@50: 0.8855, R@100: 0.9239
2024-05-01 22:06:07   Ranking results: pitts30k_val R@1: 0.9437, R@5: 0.9876, R@10: 0.9932, R@15: 0.9954, R@20: 0.9965, R@50: 0.9987, R@100: 0.9996
2024-05-01 22:07:04   Ranking results: pitts30k_test R@1: 0.9090, R@5: 0.9544, R@10: 0.9667, R@15: 0.9727, R@20: 0.9762, R@50: 0.9859, R@100: 0.9903
2024-05-01 22:12:48   Ranking results: pitts250k_test R@1: 0.9383, R@5: 0.9792, R@10: 0.9872, R@15: 0.9912, R@20: 0.9929, R@50: 0.9952, R@100: 0.9970
2024-05-01 22:18:03   Ranking results: pitts250k_val R@1: 0.9422, R@5: 0.9859, R@10: 0.9915, R@15: 0.9941, R@20: 0.9950, R@50: 0.9979, R@100: 0.9992
