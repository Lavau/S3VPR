2024-05-01 07:50:28   Arguments: Namespace(aggregator_name='token_module', backbone_name='vit_b_16', device='cuda', dim=768, epochs_num=80, foundation_model_path='pth/dinov2_vitb14_pretrain.pth', infer_batch_size=300, kernel_size=3, lr=0.0001, mlp_ratio=0.75, nc=4096, num_trainable_blocks=4, num_workers=4, optim='adam', patience=3, recall_values=[1, 5, 10, 100], resize=[224, 224], save_dir='logs/2024-05-01_07-50-28', seed=0, train_batch_size=160, val_set_names=['msls_val'])
2024-05-01 07:50:28   The outputs are being saved in logs/2024-05-01_07-50-28
2024-05-01 07:50:28   validation dataset names:['msls_val']
2024-05-01 07:50:28   Using 2 GPUs and 64 CPUs
2024-05-01 07:50:32   GeoLocalizationNet(
  (backbone): ViT(
    (model): VisionTransformer(
      (conv_proj): Conv2d(3, 768, kernel_size=(16, 16), stride=(16, 16))
      (encoder): Encoder(
        (dropout): Dropout(p=0.0, inplace=False)
        (layers): Sequential(
          (encoder_layer_0): EncoderBlock(
            (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
            (self_attention): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (dropout): Dropout(p=0.0, inplace=False)
            (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
            (mlp): MLPBlock(
              (0): Linear(in_features=768, out_features=3072, bias=True)
              (1): GELU(approximate='none')
              (2): Dropout(p=0.0, inplace=False)
              (3): Linear(in_features=3072, out_features=768, bias=True)
              (4): Dropout(p=0.0, inplace=False)
            )
          )
          (encoder_layer_1): EncoderBlock(
            (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
            (self_attention): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (dropout): Dropout(p=0.0, inplace=False)
            (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
            (mlp): MLPBlock(
              (0): Linear(in_features=768, out_features=3072, bias=True)
              (1): GELU(approximate='none')
              (2): Dropout(p=0.0, inplace=False)
              (3): Linear(in_features=3072, out_features=768, bias=True)
              (4): Dropout(p=0.0, inplace=False)
            )
          )
          (encoder_layer_2): EncoderBlock(
            (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
            (self_attention): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (dropout): Dropout(p=0.0, inplace=False)
            (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
            (mlp): MLPBlock(
              (0): Linear(in_features=768, out_features=3072, bias=True)
              (1): GELU(approximate='none')
              (2): Dropout(p=0.0, inplace=False)
              (3): Linear(in_features=3072, out_features=768, bias=True)
              (4): Dropout(p=0.0, inplace=False)
            )
          )
          (encoder_layer_3): EncoderBlock(
            (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
            (self_attention): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (dropout): Dropout(p=0.0, inplace=False)
            (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
            (mlp): MLPBlock(
              (0): Linear(in_features=768, out_features=3072, bias=True)
              (1): GELU(approximate='none')
              (2): Dropout(p=0.0, inplace=False)
              (3): Linear(in_features=3072, out_features=768, bias=True)
              (4): Dropout(p=0.0, inplace=False)
            )
          )
          (encoder_layer_4): EncoderBlock(
            (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
            (self_attention): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (dropout): Dropout(p=0.0, inplace=False)
            (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
            (mlp): MLPBlock(
              (0): Linear(in_features=768, out_features=3072, bias=True)
              (1): GELU(approximate='none')
              (2): Dropout(p=0.0, inplace=False)
              (3): Linear(in_features=3072, out_features=768, bias=True)
              (4): Dropout(p=0.0, inplace=False)
            )
          )
          (encoder_layer_5): EncoderBlock(
            (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
            (self_attention): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (dropout): Dropout(p=0.0, inplace=False)
            (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
            (mlp): MLPBlock(
              (0): Linear(in_features=768, out_features=3072, bias=True)
              (1): GELU(approximate='none')
              (2): Dropout(p=0.0, inplace=False)
              (3): Linear(in_features=3072, out_features=768, bias=True)
              (4): Dropout(p=0.0, inplace=False)
            )
          )
          (encoder_layer_6): EncoderBlock(
            (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
            (self_attention): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (dropout): Dropout(p=0.0, inplace=False)
            (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
            (mlp): MLPBlock(
              (0): Linear(in_features=768, out_features=3072, bias=True)
              (1): GELU(approximate='none')
              (2): Dropout(p=0.0, inplace=False)
              (3): Linear(in_features=3072, out_features=768, bias=True)
              (4): Dropout(p=0.0, inplace=False)
            )
          )
          (encoder_layer_7): EncoderBlock(
            (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
            (self_attention): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (dropout): Dropout(p=0.0, inplace=False)
            (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
            (mlp): MLPBlock(
              (0): Linear(in_features=768, out_features=3072, bias=True)
              (1): GELU(approximate='none')
              (2): Dropout(p=0.0, inplace=False)
              (3): Linear(in_features=3072, out_features=768, bias=True)
              (4): Dropout(p=0.0, inplace=False)
            )
          )
          (encoder_layer_8): EncoderBlock(
            (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
            (self_attention): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (dropout): Dropout(p=0.0, inplace=False)
            (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
            (mlp): MLPBlock(
              (0): Linear(in_features=768, out_features=3072, bias=True)
              (1): GELU(approximate='none')
              (2): Dropout(p=0.0, inplace=False)
              (3): Linear(in_features=3072, out_features=768, bias=True)
              (4): Dropout(p=0.0, inplace=False)
            )
          )
          (encoder_layer_9): EncoderBlock(
            (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
            (self_attention): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (dropout): Dropout(p=0.0, inplace=False)
            (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
            (mlp): MLPBlock(
              (0): Linear(in_features=768, out_features=3072, bias=True)
              (1): GELU(approximate='none')
              (2): Dropout(p=0.0, inplace=False)
              (3): Linear(in_features=3072, out_features=768, bias=True)
              (4): Dropout(p=0.0, inplace=False)
            )
          )
          (encoder_layer_10): EncoderBlock(
            (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
            (self_attention): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (dropout): Dropout(p=0.0, inplace=False)
            (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
            (mlp): MLPBlock(
              (0): Linear(in_features=768, out_features=3072, bias=True)
              (1): GELU(approximate='none')
              (2): Dropout(p=0.0, inplace=False)
              (3): Linear(in_features=3072, out_features=768, bias=True)
              (4): Dropout(p=0.0, inplace=False)
            )
          )
          (encoder_layer_11): EncoderBlock(
            (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
            (self_attention): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (dropout): Dropout(p=0.0, inplace=False)
            (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
            (mlp): MLPBlock(
              (0): Linear(in_features=768, out_features=3072, bias=True)
              (1): GELU(approximate='none')
              (2): Dropout(p=0.0, inplace=False)
              (3): Linear(in_features=3072, out_features=768, bias=True)
              (4): Dropout(p=0.0, inplace=False)
            )
          )
        )
        (ln): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      )
      (heads): Sequential(
        (head): Linear(in_features=768, out_features=1000, bias=True)
      )
    )
  )
  (aggregator): TokenMudule(
    (token_block): TokenBlock(
      (space_self_aware): SpaceSelfAware(
        (pad): ZeroPad2d((1, 1, 2, 0))
        (unfold): Unfold(kernel_size=(3, 3), dilation=1, padding=0, stride=1)
      )
      (space_fusion): Sequential(
        (0): L2Norm()
        (1): GeneralizedMeanPooling(3.0, output_size=1)
      )
      (channel): Mlp(
        (fc1): Linear(in_features=768, out_features=576, bias=True)
        (act): GELU(approximate='none')
        (drop1): Dropout(p=0.0, inplace=False)
        (fc2): Linear(in_features=576, out_features=768, bias=True)
        (drop2): Dropout(p=0.0, inplace=False)
      )
    )
    (head): GeMHead(
      (pool): GeneralizedMeanPooling(3.0, output_size=1)
      (fc): Linear(in_features=768, out_features=4096, bias=True)
    )
  )
)
2024-05-01 07:50:33   Val set: < MSLS, msls-val - #database: 18871; #queries: 747 >
2024-05-01 07:50:33   Start training epoch: 00
2024-05-01 08:22:36   Finished epoch 00 in 0:32:03, average epoch loss = 1.1627
2024-05-01 08:24:05   Ranking results: msls_val R@1: 0.5473, R@5: 0.7189, R@10: 0.7662, R@15: 0.7919, R@20: 0.8135, R@50: 0.8581, R@100: 0.8919
2024-05-01 08:24:08   Improved: previous msls-val best R@1 = 0.0000, current R@1 = 0.5473
2024-05-01 08:24:08   Start training epoch: 01
2024-05-01 08:57:08   Finished epoch 01 in 0:33:00, average epoch loss = 0.9376
2024-05-01 08:58:37   Ranking results: msls_val R@1: 0.6095, R@5: 0.7568, R@10: 0.7878, R@15: 0.8149, R@20: 0.8392, R@50: 0.8743, R@100: 0.9081
2024-05-01 08:58:44   Improved: previous msls-val best R@1 = 0.5473, current R@1 = 0.6095
2024-05-01 08:58:44   Start training epoch: 02
2024-05-01 09:31:35   Finished epoch 02 in 0:32:50, average epoch loss = 0.8760
2024-05-01 09:33:04   Ranking results: msls_val R@1: 0.6338, R@5: 0.7689, R@10: 0.8243, R@15: 0.8392, R@20: 0.8486, R@50: 0.8838, R@100: 0.9149
2024-05-01 09:33:12   Improved: previous msls-val best R@1 = 0.6095, current R@1 = 0.6338
2024-05-01 09:33:12   Start training epoch: 03
2024-05-01 10:06:11   Finished epoch 03 in 0:32:59, average epoch loss = 0.8264
2024-05-01 10:07:39   Ranking results: msls_val R@1: 0.6473, R@5: 0.7932, R@10: 0.8203, R@15: 0.8405, R@20: 0.8527, R@50: 0.8865, R@100: 0.9149
2024-05-01 10:07:47   Improved: previous msls-val best R@1 = 0.6338, current R@1 = 0.6473
2024-05-01 10:07:47   Start training epoch: 04
2024-05-01 10:40:44   Finished epoch 04 in 0:32:57, average epoch loss = 0.8037
2024-05-01 10:42:13   Ranking results: msls_val R@1: 0.6608, R@5: 0.7892, R@10: 0.8189, R@15: 0.8405, R@20: 0.8662, R@50: 0.8919, R@100: 0.9176
2024-05-01 10:42:21   Improved: previous msls-val best R@1 = 0.6473, current R@1 = 0.6608
2024-05-01 10:42:21   Start training epoch: 05
2024-05-01 11:15:16   Finished epoch 05 in 0:32:55, average epoch loss = 0.7879
2024-05-01 11:16:45   Ranking results: msls_val R@1: 0.6608, R@5: 0.7851, R@10: 0.8243, R@15: 0.8473, R@20: 0.8649, R@50: 0.9000, R@100: 0.9203
2024-05-01 11:16:49   Not improved: 1 / 3: msls-val best R@1 = 0.6608, current R@1 = 0.6608
2024-05-01 11:16:49   Start training epoch: 06
2024-05-01 11:49:46   Finished epoch 06 in 0:32:57, average epoch loss = 0.7639
2024-05-01 11:51:15   Ranking results: msls_val R@1: 0.6676, R@5: 0.7986, R@10: 0.8270, R@15: 0.8541, R@20: 0.8622, R@50: 0.8973, R@100: 0.9162
2024-05-01 11:51:21   Improved: previous msls-val best R@1 = 0.6608, current R@1 = 0.6676
2024-05-01 11:51:21   Start training epoch: 07
2024-05-01 12:23:56   Finished epoch 07 in 0:32:34, average epoch loss = 0.7554
2024-05-01 12:25:24   Ranking results: msls_val R@1: 0.6649, R@5: 0.7946, R@10: 0.8203, R@15: 0.8541, R@20: 0.8676, R@50: 0.8973, R@100: 0.9243
2024-05-01 12:25:28   Not improved: 1 / 3: msls-val best R@1 = 0.6676, current R@1 = 0.6649
2024-05-01 12:25:28   Start training epoch: 08
2024-05-01 12:58:26   Finished epoch 08 in 0:32:58, average epoch loss = 0.7464
2024-05-01 12:59:54   Ranking results: msls_val R@1: 0.6635, R@5: 0.7959, R@10: 0.8270, R@15: 0.8419, R@20: 0.8622, R@50: 0.8973, R@100: 0.9230
2024-05-01 12:59:58   Not improved: 2 / 3: msls-val best R@1 = 0.6676, current R@1 = 0.6635
2024-05-01 12:59:58   Start training epoch: 09
2024-05-01 13:32:55   Finished epoch 09 in 0:32:57, average epoch loss = 0.7351
2024-05-01 13:34:23   Ranking results: msls_val R@1: 0.6770, R@5: 0.7932, R@10: 0.8243, R@15: 0.8500, R@20: 0.8662, R@50: 0.9027, R@100: 0.9243
2024-05-01 13:34:30   Improved: previous msls-val best R@1 = 0.6676, current R@1 = 0.6770
2024-05-01 13:34:30   Start training epoch: 10
2024-05-01 14:07:23   Finished epoch 10 in 0:32:52, average epoch loss = 0.7304
2024-05-01 14:08:51   Ranking results: msls_val R@1: 0.6730, R@5: 0.7986, R@10: 0.8216, R@15: 0.8514, R@20: 0.8649, R@50: 0.9000, R@100: 0.9243
2024-05-01 14:08:54   Not improved: 1 / 3: msls-val best R@1 = 0.6770, current R@1 = 0.6730
2024-05-01 14:08:54   Start training epoch: 11
2024-05-01 14:41:52   Finished epoch 11 in 0:32:57, average epoch loss = 0.7240
2024-05-01 14:43:20   Ranking results: msls_val R@1: 0.6743, R@5: 0.7932, R@10: 0.8270, R@15: 0.8459, R@20: 0.8622, R@50: 0.8959, R@100: 0.9203
2024-05-01 14:43:24   Not improved: 2 / 3: msls-val best R@1 = 0.6770, current R@1 = 0.6743
2024-05-01 14:43:24   Start training epoch: 12
2024-05-01 15:16:24   Finished epoch 12 in 0:33:00, average epoch loss = 0.7218
2024-05-01 15:17:51   Ranking results: msls_val R@1: 0.6716, R@5: 0.7973, R@10: 0.8270, R@15: 0.8527, R@20: 0.8676, R@50: 0.8986, R@100: 0.9203
2024-05-01 15:17:55   Not improved: 3 / 3: msls-val best R@1 = 0.6770, current R@1 = 0.6716
2024-05-01 15:17:55   Performance did not improve for 3 epochs. Stop training.
2024-05-01 15:17:55   Best  msls-val best R@1 = 0.6770
2024-05-01 15:17:55   Trained for 13 epochs, in total in 7:27:27
2024-05-01 15:17:55   Val set: < MSLS, msls-val - #database: 18871; #queries: 747 >
2024-05-01 15:17:55   Val set: < Tokyo247Dataset, Tokyo - #database: 75984; #queries: 423 >
2024-05-01 15:17:55   Val set: < SPEDDataset, SPED - #database: 607; #queries: 607 >
2024-05-01 15:17:55   Val set: < NordlandDataset, nordland - #database: 27592; #queries: 2760 >
2024-05-01 15:17:56   Val set: < WholeDatasetFromStruct, pitts30k_val - #database: 10000; #queries: 7608 >
2024-05-01 15:17:56   Val set: < WholeDatasetFromStruct, pitts30k_test - #database: 10000; #queries: 6816 >
2024-05-01 15:17:56   Val set: < WholeDatasetFromStruct, pitts250k_test - #database: 83952; #queries: 8280 >
2024-05-01 15:17:57   Val set: < WholeDatasetFromStruct, pitts250k_val - #database: 78648; #queries: 7608 >
2024-05-01 15:17:57   Test *best* model on test set
2024-05-01 15:19:26   Ranking results: msls_val R@1: 0.6770, R@5: 0.7932, R@10: 0.8243, R@15: 0.8500, R@20: 0.8662, R@50: 0.9027, R@100: 0.9243
2024-05-01 15:25:48   Ranking results: tokyo247 R@1: 0.4846, R@5: 0.6785, R@10: 0.7329, R@15: 0.7660, R@20: 0.7825, R@50: 0.8511, R@100: 0.8794
2024-05-01 15:25:55   Ranking results: SPED R@1: 0.6310, R@5: 0.7562, R@10: 0.8089, R@15: 0.8451, R@20: 0.8583, R@50: 0.9209, R@100: 0.9489
2024-05-01 15:28:18   Ranking results: nordland R@1: 0.0703, R@5: 0.1304, R@10: 0.1627, R@15: 0.1888, R@20: 0.2098, R@50: 0.2819, R@100: 0.3514
2024-05-01 15:29:47   Ranking results: pitts30k_val R@1: 0.8368, R@5: 0.9577, R@10: 0.9766, R@15: 0.9842, R@20: 0.9878, R@50: 0.9965, R@100: 0.9982
2024-05-01 15:31:11   Ranking results: pitts30k_test R@1: 0.8207, R@5: 0.9193, R@10: 0.9440, R@15: 0.9550, R@20: 0.9611, R@50: 0.9767, R@100: 0.9839
2024-05-01 15:39:23   Ranking results: pitts250k_test R@1: 0.8339, R@5: 0.9385, R@10: 0.9586, R@15: 0.9679, R@20: 0.9722, R@50: 0.9836, R@100: 0.9897
2024-05-01 15:46:56   Ranking results: pitts250k_val R@1: 0.8237, R@5: 0.9369, R@10: 0.9566, R@15: 0.9652, R@20: 0.9706, R@50: 0.9838, R@100: 0.9913
2024-05-01 15:46:56   Test *last* model on test set
2024-05-01 15:48:09   Ranking results: msls_val R@1: 0.6716, R@5: 0.7973, R@10: 0.8270, R@15: 0.8527, R@20: 0.8676, R@50: 0.8986, R@100: 0.9203
2024-05-01 15:54:22   Ranking results: tokyo247 R@1: 0.4894, R@5: 0.6738, R@10: 0.7305, R@15: 0.7683, R@20: 0.7872, R@50: 0.8511, R@100: 0.8842
2024-05-01 15:54:27   Ranking results: SPED R@1: 0.6293, R@5: 0.7496, R@10: 0.8155, R@15: 0.8484, R@20: 0.8633, R@50: 0.9143, R@100: 0.9456
2024-05-01 15:56:15   Ranking results: nordland R@1: 0.0728, R@5: 0.1341, R@10: 0.1649, R@15: 0.1895, R@20: 0.2105, R@50: 0.2895, R@100: 0.3580
2024-05-01 15:57:25   Ranking results: pitts30k_val R@1: 0.8377, R@5: 0.9572, R@10: 0.9775, R@15: 0.9837, R@20: 0.9880, R@50: 0.9966, R@100: 0.9983
2024-05-01 15:58:33   Ranking results: pitts30k_test R@1: 0.8212, R@5: 0.9180, R@10: 0.9435, R@15: 0.9541, R@20: 0.9605, R@50: 0.9761, R@100: 0.9842
2024-05-01 16:06:08   Ranking results: pitts250k_test R@1: 0.8342, R@5: 0.9393, R@10: 0.9586, R@15: 0.9681, R@20: 0.9728, R@50: 0.9832, R@100: 0.9897
2024-05-01 16:12:49   Ranking results: pitts250k_val R@1: 0.8245, R@5: 0.9369, R@10: 0.9581, R@15: 0.9660, R@20: 0.9706, R@50: 0.9844, R@100: 0.9915
